{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning\n",
    "This notebook is under development- please use to evaluate entropy notebook and suggest desired changes only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on precision fitting arrays and reality\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Part I: import libraries](#imports)\n",
    "    \n",
    "Part II: lookign at EMG versus Drager\n",
    "    \n",
    "Part III: squish or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries\n",
    "<a id= 'imports'> Import libraries for all code</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "import collections\n",
    "from collections import namedtuple\n",
    "import builtins\n",
    "import math\n",
    "import scipy\n",
    "from scipy.signal import find_peaks\n",
    "#from TMSiSDK.file_readers import Poly5Reader\n",
    "# import our library\n",
    "#sys.path.insert(0, '../resurfemg')\n",
    "import resurfemg.helper_functions as hf\n",
    "from pandas import option_context\n",
    "from resurfemg.config import Config\n",
    "\n",
    "# config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\makeda\\anaconda3\\envs\\emgandash\\lib\\site-packages\\mne\\fixes.py:321: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(scipy.__version__) >= '1.1':\n",
      "C:\\Users\\makeda\\anaconda3\\envs\\emgandash\\lib\\site-packages\\mne\\fixes.py:1134: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numba.__version__) < LooseVersion('0.40'):\n",
      "C:\\Users\\makeda\\anaconda3\\envs\\emgandash\\lib\\site-packages\\mne\\fixes.py:1134: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if LooseVersion(numba.__version__) < LooseVersion('0.40'):\n"
     ]
    }
   ],
   "source": [
    "sys.path.insert(0, '../resurfemg')\n",
    "import tsmisdk_lite as tl\n",
    "#from "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING!\n",
    "# The cell below must be eliminated on next release v0.0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a collection place for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not rerun this cell\n",
    "big_data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below change the path to the root directory where you are keeping your EMGs and ventilator \"Draeger\" files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reruns should be done from this cell as the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_emg_directory = config.get_directory('root_emg_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_draeger_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "draeger_files = []\n",
    "\n",
    "for file in emg_and_draeger_files:\n",
    "    if 'Draeger' in file:\n",
    "        draeger_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pick a file from the list, which have been numbered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6f6d7e4bbbb4ffea9f8b285dd1b71ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dropdown(description='Picked File:', options=('0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '1â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "list_of_numbers_strung = []\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_strung.append(str(i))\n",
    "\n",
    "\n",
    "btn = widgets.Dropdown(\n",
    "    options=list_of_numbers_strung,\n",
    "    value='0',\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caution! \n",
    "If you folder is set up in any way different then the picked file numbers will not neccesarily correspond to the same file. Always check the print out for the file you have chosen in the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files you chose are:\n",
      " C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\EMG_recording.Poly5 \n",
      " C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\Draeger_recording.Poly5\n"
     ]
    }
   ],
   "source": [
    "number_chosen = int(btn.value)\n",
    "emg_file_chosen = emg_files[number_chosen]\n",
    "draeger_file_chosen = draeger_files[number_chosen]\n",
    "print(\"The files you chose are:\\n\", emg_file_chosen, '\\n', draeger_file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\EMG_recording.Poly5\n",
      "\t Number of samples:  172576 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n"
     ]
    }
   ],
   "source": [
    "data_emg = tl.Poly5Reader(emg_file_chosen)\n",
    "data_samples= data_emg.samples\n",
    "emg_sample_rate = data_emg.sample_rate\n",
    "converted_to_seconds =  []\n",
    "converted_to_samples = []\n",
    "for i in range(len(data_samples[0])):\n",
    "    converted_to_seconds.append(i/emg_sample_rate)\n",
    "    converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\Draeger_recording.Poly5\n",
      "\t Number of samples:  8421 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n"
     ]
    }
   ],
   "source": [
    "data_drag = tl.Poly5Reader(draeger_file_chosen)\n",
    "data_drag_samples= data_drag.samples\n",
    "drag_sample_rate =  data_drag.sample_rate\n",
    "d_converted_to_seconds =  []\n",
    "d_converted_to_samples = []\n",
    "for i in range(len(data_drag_samples[0])):\n",
    "    d_converted_to_seconds.append(i/drag_sample_rate)\n",
    "    d_converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.05562500000000625"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(data_drag_samples[1])/100)- (len(data_samples[1])/2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\007\\Draeger_recording.Poly5\n",
      "\t Number of samples:  36490 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\007\\EMG_recording.Poly5\n",
      "\t Number of samples:  747360 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\008\\Draeger_recording.Poly5\n",
      "\t Number of samples:  30841 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\008\\EMG_recording.Poly5\n",
      "\t Number of samples:  631504 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\009\\Draeger_recording.Poly5\n",
      "\t Number of samples:  38903 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\009\\EMG_recording.Poly5\n",
      "\t Number of samples:  796800 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\001\\Draeger_recording.Poly5\n",
      "\t Number of samples:  27652 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\001\\EMG_recording.Poly5\n",
      "\t Number of samples:  566448 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\002\\Draeger_recording.Poly5\n",
      "\t Number of samples:  35930 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\002\\EMG_recording.Poly5\n",
      "\t Number of samples:  736096 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\003\\Draeger_recording.Poly5\n",
      "\t Number of samples:  52596 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\003\\EMG_recording.Poly5\n",
      "\t Number of samples:  1077648 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\004\\Draeger_recording.Poly5\n",
      "\t Number of samples:  45507 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\004\\EMG_recording.Poly5\n",
      "\t Number of samples:  932288 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\005\\Draeger_recording.Poly5\n",
      "\t Number of samples:  44314 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\005\\EMG_recording.Poly5\n",
      "\t Number of samples:  907792 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\006\\Draeger_recording.Poly5\n",
      "\t Number of samples:  40698 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\006\\EMG_recording.Poly5\n",
      "\t Number of samples:  833872 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\007\\Draeger_recording.Poly5\n",
      "\t Number of samples:  48202 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M004\\007\\EMG_recording.Poly5\n",
      "\t Number of samples:  987376 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg</th>\n",
       "      <th>draeg</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.021875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>0.058438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.065938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.121875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.235312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.14875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.117813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.184062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.097188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 emg  \\\n",
       "0  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "1  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "2  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "3  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "4  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "5  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "6  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "7  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "8  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "9  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "\n",
       "                                               draeg      diff  \n",
       "0  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.021875  \n",
       "1  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  0.058438  \n",
       "2  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   -0.0325  \n",
       "3  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.065938  \n",
       "4  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.121875  \n",
       "5  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.235312  \n",
       "6  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.14875  \n",
       "7  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.117813  \n",
       "8  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.184062  \n",
       "9  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.097188  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_end_list = []  \n",
    "emg_file_end_list = []\n",
    "draeger_file_end_list = []\n",
    "for num in list(range(25,35)): #len(emg_files))):\n",
    "          \n",
    "    number_chosen = int(num)\n",
    "    emg_file_chosen = emg_files[number_chosen]\n",
    "    draeger_file_chosen = draeger_files[number_chosen]\n",
    "    data_drag = tl.Poly5Reader(draeger_file_chosen)\n",
    "    data_drag_samples= data_drag.samples\n",
    "    data_emg = tl.Poly5Reader(emg_file_chosen)\n",
    "    data_samples= data_emg.samples\n",
    "    longer = (len(data_drag_samples[1])/100) - (len(data_samples[1])/2048)\n",
    "    diff_end_list.append(longer)\n",
    "    emg_file_end_list.append(emg_file_chosen) \n",
    "    draeger_file_end_list.append(draeger_file_chosen) \n",
    "end_list = pd.DataFrame([emg_file_end_list, draeger_file_end_list, diff_end_list]) \n",
    "end_list = end_list.T\n",
    "end_list.columns = ['emg','draeg', 'diff']\n",
    "end_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\Draeger_recording.Poly5\n",
      "\t Number of samples:  8421 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\001\\EMG_recording.Poly5\n",
      "\t Number of samples:  172576 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\002\\Draeger_recording.Poly5\n",
      "\t Number of samples:  48746 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\002\\EMG_recording.Poly5\n",
      "\t Number of samples:  998496 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\003\\Draeger_recording.Poly5\n",
      "\t Number of samples:  42449 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\003\\EMG_recording.Poly5\n",
      "\t Number of samples:  869280 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\004\\Draeger_recording.Poly5\n",
      "\t Number of samples:  54459 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\004\\EMG_recording.Poly5\n",
      "\t Number of samples:  1115536 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\005\\Draeger_recording.Poly5\n",
      "\t Number of samples:  47504 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\005\\EMG_recording.Poly5\n",
      "\t Number of samples:  972944 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\006\\Draeger_recording.Poly5\n",
      "\t Number of samples:  37231 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\006\\EMG_recording.Poly5\n",
      "\t Number of samples:  762496 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\007\\Draeger_recording.Poly5\n",
      "\t Number of samples:  44993 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\007\\EMG_recording.Poly5\n",
      "\t Number of samples:  921584 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\008\\Draeger_recording.Poly5\n",
      "\t Number of samples:  37185 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\008\\EMG_recording.Poly5\n",
      "\t Number of samples:  761488 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\009\\Draeger_recording.Poly5\n",
      "\t Number of samples:  31968 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M001\\009\\EMG_recording.Poly5\n",
      "\t Number of samples:  654784 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\001\\Draeger_recording.Poly5\n",
      "\t Number of samples:  54567 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\001\\EMG_recording.Poly5\n",
      "\t Number of samples:  1118016 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\002\\Draeger_recording.Poly5\n",
      "\t Number of samples:  54760 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\002\\EMG_recording.Poly5\n",
      "\t Number of samples:  1121616 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\003\\Draeger_recording.Poly5\n",
      "\t Number of samples:  57045 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\003\\EMG_recording.Poly5\n",
      "\t Number of samples:  1168416 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\004\\Draeger_recording.Poly5\n",
      "\t Number of samples:  37418 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\004\\EMG_recording.Poly5\n",
      "\t Number of samples:  766560 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\005\\Draeger_recording.Poly5\n",
      "\t Number of samples:  45190 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\005\\EMG_recording.Poly5\n",
      "\t Number of samples:  925792 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\006\\Draeger_recording.Poly5\n",
      "\t Number of samples:  25902 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\006\\EMG_recording.Poly5\n",
      "\t Number of samples:  530496 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\007\\Draeger_recording.Poly5\n",
      "\t Number of samples:  29529 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\007\\EMG_recording.Poly5\n",
      "\t Number of samples:  604864 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\008\\Draeger_recording.Poly5\n",
      "\t Number of samples:  35142 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\008\\EMG_recording.Poly5\n",
      "\t Number of samples:  719840 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\009\\Draeger_recording.Poly5\n",
      "\t Number of samples:  27776 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\009\\EMG_recording.Poly5\n",
      "\t Number of samples:  568912 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\010\\Draeger_recording.Poly5\n",
      "\t Number of samples:  35142 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M002\\010\\EMG_recording.Poly5\n",
      "\t Number of samples:  719840 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\001\\Draeger_recording.Poly5\n",
      "\t Number of samples:  31639 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\001\\EMG_recording.Poly5\n",
      "\t Number of samples:  648144 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\002\\Draeger_recording.Poly5\n",
      "\t Number of samples:  43388 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\002\\EMG_recording.Poly5\n",
      "\t Number of samples:  888896 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\003\\Draeger_recording.Poly5\n",
      "\t Number of samples:  44374 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\003\\EMG_recording.Poly5\n",
      "\t Number of samples:  909104 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\004\\Draeger_recording.Poly5\n",
      "\t Number of samples:  38267 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\004\\EMG_recording.Poly5\n",
      "\t Number of samples:  783952 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\005\\Draeger_recording.Poly5\n",
      "\t Number of samples:  41605 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 100 Hz\n",
      "Done reading data.\n",
      "Reading file  C:/Projects/ReSurfEMG/not_pushed/topspin_data_anonymized\\M003\\005\\EMG_recording.Poly5\n",
      "\t Number of samples:  852208 \n",
      "\t Number of channels:  3 \n",
      "\t Sample rate: 2048 Hz\n",
      "Done reading data.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emg</th>\n",
       "      <th>draeg</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.055625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.086875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>0.036875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.105312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.030312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.062187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>0.029688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.03875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.23625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.064062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.065625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.116875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.146875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.01125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.05375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.064375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.029063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.064375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.086563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.15125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.158437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.119062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>C:/Projects/ReSurfEMG/not_pushed/topspin_data_...</td>\n",
       "      <td>-0.067187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  emg  \\\n",
       "0   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "1   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "2   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "3   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "4   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "5   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "6   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "7   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "8   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "9   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "10  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "11  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "12  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "13  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "14  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "15  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "16  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "17  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "18  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "19  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "20  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "21  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "22  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "23  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   \n",
       "\n",
       "                                                draeg      diff  \n",
       "0   C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.055625  \n",
       "1   C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.086875  \n",
       "2   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  0.036875  \n",
       "3   C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.105312  \n",
       "4   C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.030312  \n",
       "5   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...   -0.0025  \n",
       "6   C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.062187  \n",
       "7   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  0.029688  \n",
       "8   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.03875  \n",
       "9   C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.23625  \n",
       "10  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.064062  \n",
       "11  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.065625  \n",
       "12  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.116875  \n",
       "13  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.146875  \n",
       "14  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.01125  \n",
       "15  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.05375  \n",
       "16  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.064375  \n",
       "17  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.029063  \n",
       "18  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.064375  \n",
       "19  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.086563  \n",
       "20  C:/Projects/ReSurfEMG/not_pushed/topspin_data_...  -0.15125  \n",
       "21  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.158437  \n",
       "22  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.119062  \n",
       "23  C:/Projects/ReSurfEMG/not_pushed/topspin_data_... -0.067187  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_start_list = []  \n",
    "emg_file_start_list = []\n",
    "draeger_file_start_list = []\n",
    "for num in list(range(24)): #len(emg_files))):\n",
    "          \n",
    "    number_chosen = int(num)\n",
    "    emg_file_chosen = emg_files[number_chosen]\n",
    "    draeger_file_chosen = draeger_files[number_chosen]\n",
    "    data_drag = tl.Poly5Reader(draeger_file_chosen)\n",
    "    data_drag_samples= data_drag.samples\n",
    "    data_emg = tl.Poly5Reader(emg_file_chosen)\n",
    "    data_samples= data_emg.samples\n",
    "    longer = (len(data_drag_samples[1])/100) - (len(data_samples[1])/2048)\n",
    "    diff_start_list.append(longer)\n",
    "    emg_file_start_list.append(emg_file_chosen) \n",
    "    draeger_file_start_list.append(draeger_file_chosen)\n",
    "start_list = pd.DataFrame([emg_file_start_list, draeger_file_start_list, diff_start_list]) \n",
    "start_list = start_list.T\n",
    "start_list.columns = ['emg','draeg', 'diff']\n",
    "start_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = pd.concat([end_list, start_list])\n",
    "full_list.to_csv('list_of_time_differences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full_list.style.set_properties(subset=['emg','draeg'], **{'width': '300px'})\n",
    "\n",
    "\n",
    "with option_context('display.max_colwidth', 400):\n",
    "    display(full_list)\n",
    "\n",
    "#df.style.set_properties(subset=['text'], **{'width': '300px'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(diff_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part III:  the new data is it squeezed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import something we know has an exactly 22 respiratory rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d22_chosen = 'C:/Projects/ReSurfEMG/not_pushed/d22/Draeger_recording_22.Poly5'\n",
    "data_vent_22 = tl.Poly5Reader(d22_chosen)\n",
    "data_samples= data_vent_22.samples\n",
    "data_sample_rate = data_vent_22.sample_rate\n",
    "converted_to_seconds =  []\n",
    "converted_to_samples = []\n",
    "for i in range(len(data_samples[0])):\n",
    "    converted_to_seconds.append(i/data_sample_rate)\n",
    "    converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = data_samples\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 2, figsize=(16, 6))\n",
    "\n",
    "axis[0,0].grid(True)\n",
    "axis[0,0].plot(x[0])\n",
    "axis[0,0].set(title='leads in samples')\n",
    "axis[1,0].plot(x[1])\n",
    "axis[2,0].plot(x[2])\n",
    "## below needs a rewrite\n",
    "axis[0,1].set(title='leads in seconds')\n",
    "axis[0,1].grid(True)\n",
    "axis[0,1].plot(converted_to_seconds,x[0])\n",
    "axis[1,1].plot(converted_to_seconds,x[1])\n",
    "axis[2,1].plot(converted_to_seconds,x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(converted_to_seconds[0:6000],x[0][0:6000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(converted_to_seconds[6000:12000],x[0][6000:12000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ventilator_rate(vent_signal_file):\n",
    "    file_name = vent_signal_file\n",
    "    data_drag = tl.Poly5Reader(vent_signal_file)\n",
    "    data_drag_samples= data_drag.samples\n",
    "    data_drag_sample_rate = data_drag.sample_rate\n",
    "    #print(data_drag_samples)\n",
    "    peaks, _ = find_peaks(data_drag_samples[0], distance =1.9*data_drag_sample_rate,  height=0)\n",
    "    plt.plot(data_drag_samples[0])\n",
    "    plt.plot(peaks, data_drag_samples[0][peaks], \"x\")\n",
    "    plt.rcParams[\"figure.figsize\"] = (2,3)\n",
    "    rate = (len(peaks)/(len(data_drag_samples[0])/100))*60\n",
    "    time = (len(data_drag_samples[0])/100)/60\n",
    "    return rate, time, file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = []\n",
    "rate_list = []\n",
    "time_list = []\n",
    "file_list = []\n",
    "for num in list(range(24)):\n",
    "    num_list.append( num)\n",
    "    rate_list.append(find_ventilator_rate(draeger_files[num])[0])\n",
    "    time_list.append(find_ventilator_rate(draeger_files[num])[1])\n",
    "    file_list.append(find_ventilator_rate(draeger_files[num])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df =pd.DataFrame(num_list, columns = ['num'])\n",
    "rate_df['rate'] = rate_list\n",
    "rate_df['time'] = time_list\n",
    "rate_df['file'] = file_list\n",
    "rate_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_df.to_csv('rates_by_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = data_samples\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 2, figsize=(6, 6))\n",
    "#ax.set_ylim([-4, 4])\n",
    "axis[0,0].grid(True)\n",
    "axis[0,0].plot(x[0])\n",
    "axis[0,0].set(title='leads in samples')\n",
    "axis[1,0].plot(x[1])\n",
    "axis[2,0].plot(x[2])\n",
    "## needs a rewrite\n",
    "# axis[0,1].set(title='leads in seconds')\n",
    "# axis[0,1].grid(True)\n",
    "# axis[0,1].plot(converted_to_seconds,x[0])\n",
    "# axis[1,1].plot(converted_to_seconds,x[1])\n",
    "# axis[2,1].plot(converted_to_seconds,x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "z = data_samples[2]\n",
    "# fig, axis = plt.subplots(nrows = 1, ncols = 1, figsize=(16, 6))\n",
    "# #ax.set_ylim([-4, 4])\n",
    "# axis.grid(True)\n",
    "# axis.plot(x[0])\n",
    "# axis.set(title='leads in samples')\n",
    "plt.plot(z[:20000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_by_bad_end_cut = hf.bad_end_cutter_for_samples(\n",
    "        data_samples,\n",
    "        percent_to_cut=3,\n",
    "        tolerance_percent=5\n",
    "    )\n",
    "z2 = z_by_bad_end_cut[2]\n",
    "\n",
    "plt.plot(z2)\n",
    "plt.plot(z[:169478], alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(z2-z[:169478], alpha = 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " bd_filtered_file_data = hf.emg_bandpass_butter_sample(\n",
    "        z_by_bad_end_cut,\n",
    "        5,\n",
    "        450,\n",
    "        2048,\n",
    "        output='sos'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(z2)\n",
    "plt.plot(bd_filtered_file_data[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(z2))\n",
    "print(len(bd_filtered_file_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z3_3 = hf.bad_end_cutter_for_samples(\n",
    "        bd_filtered_file_data,\n",
    "        percent_to_cut=3,\n",
    "        tolerance_percent=5\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bd_filtered_file_data[0][140000:150000])\n",
    "plt.plot(z3_3[2][140000:150000], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "components = hf.compute_ICA_two_comp(z3_3)\n",
    "\n",
    "emg = hf.pick_lowest_correlation_array(components, z3_3[0])\n",
    "print(len(emg))\n",
    "print(len(z3_3[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emg[140000:150000]*10000)\n",
    "plt.plot(z3_3[2][140000:150000], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "componentsM = hf.compute_ICA_two_comp_multi(z3_3)\n",
    "\n",
    "emgM = hf.pick_lowest_correlation_array(componentsM, z3_3[0])\n",
    "print(len(emgM))\n",
    "print(len(z3_3[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emgM[140000:150000]*10000)\n",
    "plt.plot(z3_3[2][140000:150000], alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emgM[140000:150000]*10000)\n",
    "plt.plot(emg[140000:150000]*10000, alpha=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emg*1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's pre-process\n",
    "\n",
    "def working_pipeline_pre_ml(our_chosen_samples, picker='heart'):\n",
    "    \"\"\"\n",
    "    :param our_chosen_samples: the read EMG file arrays\n",
    "    :type our_chosen_samples: ~numpy.ndarray\n",
    "    :param picker: the picking strategy for independant components\n",
    "    :type picker: str\n",
    "\n",
    "    :returns: final_envelope_a\n",
    "    :rtype: ~numpy.ndarray\n",
    "    \"\"\"\n",
    "    cut_file_data = bad_end_cutter_for_samples(\n",
    "        our_chosen_samples,\n",
    "        percent_to_cut=3,\n",
    "        tolerance_percent=5\n",
    "    )\n",
    "    bd_filtered_file_data = emg_bandpass_butter_sample(\n",
    "        cut_file_data,\n",
    "        5,\n",
    "        450,\n",
    "        2048,\n",
    "        output='sos'\n",
    "    )\n",
    "    # step for end-cutting again to get rid of filtering artifacts\n",
    "    re_cut_file_data = bad_end_cutter_for_samples(\n",
    "        bd_filtered_file_data,\n",
    "        percent_to_cut=3,\n",
    "        tolerance_percent=5\n",
    "    )\n",
    "    #  and do step for ICA\n",
    "    components = compute_ICA_two_comp(re_cut_file_data)\n",
    "    #     the picking step!\n",
    "    if picker == 'peaks':\n",
    "        emg = pick_more_peaks_array(components)\n",
    "    elif picker == 'heart':\n",
    "        emg = pick_lowest_correlation_array(components, re_cut_file_data[0])\n",
    "    else:\n",
    "        emg = pick_lowest_correlation_array(components, re_cut_file_data[0])\n",
    "        print(\"Please choose an exising picker i.e. peaks or hearts \")\n",
    "    # now process it in final steps\n",
    "    abs_values = abs(emg)\n",
    "    final_envelope_d = emg_highpass_butter(abs_values, 150, 2048)\n",
    "\n",
    "    return final_envelope_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = x[:, 20000:40000]\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 1, figsize=(16, 6))\n",
    "#ax.set_ylim([-4, 4])\n",
    "axis[0].grid(True)\n",
    "axis[0].plot(x[0])\n",
    "axis[0].set(title='leads in samples')\n",
    "axis[1].plot(x[1])\n",
    "axis[2].plot(x[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_samples[0])/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(data_samples[0])/2048)/60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the whole unfiltered EMG, number 0. Let's take the real legnth, and sample rate, and double check time with ROB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Times on each sample: \n",
    "\\M001\\001\\EMG_recording.Poly5  should be about 5 minutes\n",
    "\\M001\\001\\EMG_recording.Poly5\n",
    " stable\n",
    "002-005 5 to 10 minutes\n",
    "\n",
    "006-009 5 to 10 minute, at the end each should have 3 occlusion events\n",
    "\n",
    "Sample rates on each sample: \n",
    "2048 all\n",
    "\n",
    "Known # breaths:\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you want to cut and see the file in samples or seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = widgets.Dropdown(\n",
    "    options=[\"Samples\",\"Seconds\"],\n",
    "    value='Samples',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(y_axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_view= y_axis.value\n",
    "time_view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you will pick the start and end of your sample.We are going to clip the end of the sample in processing, so you can not pick any values and get a good graph. We preset the values towards the max graphable with ease, but they can be overwritten.  In the future we will have an updating graph here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_view == 'Samples':\n",
    "    int_slider1 = widgets.IntSlider(\n",
    "        min=0, max=int(len(x[0])*0.89), step=1,\n",
    "        description=' samples start'\n",
    "    )\n",
    "    int_slider2 = widgets.IntSlider(\n",
    "        value=len(x[0]),\n",
    "        min=0, max=int(len(x[0])*0.89), step=1,\n",
    "        description='samples end cutoff'\n",
    "    )\n",
    "else:\n",
    "    int_slider1 = widgets.IntSlider(\n",
    "        #value=0.1,\n",
    "        min=0, max= int(converted_to_seconds[-1])*0.89, step=1,\n",
    "        description='seconds start'\n",
    "    )\n",
    "    int_slider2 = widgets.IntSlider(\n",
    "        #value=converted_to_seconds[-1],\n",
    "        min=0, max=int(converted_to_seconds[-1])*0.89, step= 1,\n",
    "        description='seconds end cutoff'\n",
    "    )\n",
    "    \n",
    "widgets.VBox(\n",
    "    [\n",
    "\n",
    "        int_slider1,\n",
    "        int_slider2,\n",
    "\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can overwrite the values by hand in the next cell, if scrolling is not precise enough...but rewriting to take an absolute end is unadvisable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # # Here we can overwrite the values by hand, again you must pick values a bit inside\n",
    "# int_slider1.value = 1\n",
    "# int_slider2.value = 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now we will graph your choice in the next active cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = int_slider1.value\n",
    "end= int_slider2.value\n",
    "if time_view == 'Samples':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x = data_samples\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(x[0][int(start):int(end)])\n",
    "    ax_1.set(title='leads, samples')\n",
    "    ax_2.plot(x[1][int(start):int(end)])\n",
    "    ax_3.plot(x[2][int(start):int(end)])\n",
    "    \n",
    "if time_view == 'Seconds':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x_for_secs = data_samples\n",
    "\n",
    "    y = converted_to_seconds\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[0][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    ax_1.set(title='leads, seconds')\n",
    "    ax_2.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[1][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    ax_3.plot(y[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[2][int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy with your selection? If not redo the widgeted cell, then we can see how the filter the selection in a basic pipleline before extracting entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropdown to pick ICA possibilities. CUrrently only one -\\o/-\n",
    "ICA_choice = widgets.Dropdown(\n",
    "    options=[\"classic\",\"no_ica_lead3\"],\n",
    "    value='classic',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(ICA_choice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will have to rewrite to accomodate different ICAs, but this is in the future. After we iron out the alternative ICAs. Below we put our EMG data through the pipeline we have now, and we must do picking from an ICA by more peaks or by dis-similarity to the heart/ECG lead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_picker_choice = widgets.Dropdown(\n",
    "    options=[\"more_peaks\",\"similar_to_ECG\"],\n",
    "    value='more_peaks',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(ICA_picker_choice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ICA_picker_choice.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_pipeline_pre_entropy_peaks(our_chosen_samples): \n",
    "    cut_file_data = hf.bad_end_cutter_for_samples(our_chosen_samples, percent_to_cut=3, tolerance_percent=5)\n",
    "    bd_filtered_file_data = hf.emg_bandpass_butter_sample(cut_file_data, 5, 450, 2048, output='sos')\n",
    "    # step 3 end-cutting again to get rid of filtering artifacts\n",
    "    re_cut_file_data = hf.bad_end_cutter_for_samples(bd_filtered_file_data, percent_to_cut=3, tolerance_percent=5)\n",
    "    # skip step4 and do step 5 ICA\n",
    "    components = hf.compute_ICA_two_comp(re_cut_file_data)\n",
    "    #     the picking step!\n",
    "    emg= hf.pick_more_peaks_array(components)\n",
    "    # now process it in final steps\n",
    "    abs_values = abs(emg)\n",
    "    final_envelope_d = hf.emg_highpass_butter(abs_values, 150, 2048)\n",
    "    \n",
    "        \n",
    "    return final_envelope_d\n",
    "\n",
    "def working_pipeline_pre_entropy_ecg(our_chosen_samples): \n",
    "    cut_file_data = hf.bad_end_cutter_for_samples(our_chosen_samples, percent_to_cut=3, tolerance_percent=5)\n",
    "    bd_filtered_file_data = hf.emg_bandpass_butter_sample(cut_file_data, 5, 450, 2048, output='sos')\n",
    "    # step 3 end-cutting again to get rid of filtering artifacts\n",
    "    re_cut_file_data = hf.bad_end_cutter_for_samples(bd_filtered_file_data, percent_to_cut=3, tolerance_percent=5)\n",
    "    # skip step4 and do step 5 ICA\n",
    "    components = hf.compute_ICA_two_comp(re_cut_file_data)\n",
    "    #     the picking step!\n",
    "    emg= hf.pick_lowest_correlation_array(components,re_cut_file_data[0] )\n",
    "    # now process it in final steps\n",
    "    abs_values = abs(emg)\n",
    "    final_envelope_d = hf.emg_highpass_butter(abs_values, 150, 2048)\n",
    "    \n",
    "        \n",
    "    return final_envelope_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's examine our processed EMG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ICA_picker_choice.value == 'more_peaks':\n",
    "    processed_data_emg = working_pipeline_pre_entropy_peaks(data_samples)\n",
    "elif ICA_picker_choice.value == 'similar_to_ECG':\n",
    "    processed_data_emg = working_pipeline_pre_entropy_ecg(data_samples)\n",
    "else:\n",
    "    processed_data_emg = working_pipeline_pre_entropy_ecg(data_samples)\n",
    "\n",
    "if time_view == 'Seconds':\n",
    "    %matplotlib inline\n",
    "    # set up plotn\n",
    "    x = processed_data_emg\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize=(14, 6))\n",
    "    axis[0].grid(True)\n",
    "    axis[0].plot(converted_to_seconds[:len(x)], x)\n",
    "    axis[0].set(title='The whole sample minus last filter lost end')\n",
    "    axis[1].set(title='Your picked area in seconds')\n",
    "    axis[1].grid(True)\n",
    "    axis[1].plot(converted_to_seconds[int(start*emg_sample_rate):int(end*emg_sample_rate)],x[int(start*emg_sample_rate):int(end*emg_sample_rate)])\n",
    "else:\n",
    "    %matplotlib inline\n",
    "    x = processed_data_emg\n",
    "    fig, axis = plt.subplots(nrows = 1, ncols = 2, figsize=(14, 6))\n",
    "    axis[0].grid(True)\n",
    "    axis[0].plot(x)\n",
    "    axis[0].set(title='The whole sample minus last filter lost end')\n",
    "    axis[1].set(title='Your picked area in samples')\n",
    "    axis[1].grid(True)\n",
    "    axis[1].plot(converted_to_samples[int(start):int(end)],x[int(start):int(end)])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we created some basic processed EMG. We will graph it based on the sample selected and the cutoff on entropy. We will ultimately do a cut-off based on something popular in the literature, but let's do one based on one simple parameter first, as an example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9 breaths per 40,000 samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "40000/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(9/19.53125)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(8/19.53125)*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to select where the cut_off is\n",
    "\n",
    "entropy_cutoff = widgets.Dropdown(\n",
    "    options=[\"Mean\",\"Half_range\"],\n",
    "    value='Mean',\n",
    "    description=\"Select Entropy Cut off\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(entropy_cutoff)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_for_ent(stralist):\n",
    "    rounded= np.round_(stralist, decimals = 5)\n",
    "    return rounded\n",
    "start_s= start * emg_sample_rate\n",
    "end_s = end * emg_sample_rate\n",
    "if time_view == 'Samples':\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start):int(end)])# replace with whole array of time series!\n",
    "else:\n",
    "   \n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start_s):int(end_s)])\n",
    "slice_length = 100\n",
    "def sliceIterator(lst, sliceLen):\n",
    "    for i in range(len(lst) - sliceLen + 1):\n",
    "        yield lst[i:i + sliceLen]\n",
    "index_hold = []\n",
    "for slice in sliceIterator(big_list, slice_length):\n",
    "    entropy_index = hf.entropical(slice)\n",
    "    index_hold.append(entropy_index)\n",
    "\n",
    "if entropy_cutoff.value == 'Half_range':\n",
    "    decision_cutoff = (np.max(index_hold) + np.min(index_hold))/2\n",
    "else:# entropy_cutoff.value == 'Mean':\n",
    "    decision_cutoff = np.mean(index_hold)\n",
    "\n",
    "\n",
    "rms_rolled = hf.vect_naive_rolling_rms(index_hold,100) # so rms is rms entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how we would have split it on that criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_view == 'Samples':\n",
    "    #y= converted_to_samples\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],rms_rolled)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    \n",
    "else:\n",
    "    y = converted_to_seconds\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))], processed_data_emg[int(start_s):(int(start_s)+len(rms_rolled))]*1000)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],rms_rolled)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above picture the green line represents a 0,1, array which represents the breaths. That picking was based on one simple parameter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changes here!\n",
    "Instead of above code we will do\n",
    "pick breath based on 90% entropy\n",
    "then 50%- this will give start of breath\n",
    "define peak value within 90%\n",
    "moving forward to right 70%-> with smoothing away if there is too short a pause. This is a more complicated algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reminder\n",
    "time_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def rounded_for_ent(stralist):\n",
    "    rounded= np.round_(stralist, decimals = 5)\n",
    "    return rounded\n",
    "if time_view == 'Samples':\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start):int(end)])# replace with whole array of time series!\n",
    "else:\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start_s):int(end_s)])\n",
    "slice_length = 100\n",
    "def sliceIterator(lst, sliceLen):\n",
    "    for i in range(len(lst) - sliceLen + 1):\n",
    "        yield lst[i:i + sliceLen]\n",
    "index_hold = []\n",
    "for slice in sliceIterator(big_list, slice_length):\n",
    "    entropy_index = hf.entropical(slice)\n",
    "    index_hold.append(entropy_index)\n",
    "\n",
    "high_decision_cutoff = 0.9  * ((np.max(index_hold)) - (np.min(index_hold))) + np.min(index_hold)\n",
    "decision_cutoff = 0.5 * ((np.max(index_hold)) - (np.min(index_hold))) + np.min(index_hold)\n",
    "\n",
    "rms_rolled = hf.vect_naive_rolling_rms(index_hold,100) # so rms is rms entropy\n",
    "\n",
    "\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],rms_rolled)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color= 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    \n",
    "else:\n",
    "    y = converted_to_seconds\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))], processed_data_emg[int(start_s):(int(start_s)+len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],rms_rolled)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color = 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(left, right):\n",
    "    # Initialize an empty list output that will be populated with sorted elements.\n",
    "    # Initialize two variables i and j which are used pointers when iterating through the lists.\n",
    "    output = []\n",
    "    i = j = 0\n",
    "\n",
    "    # Executes the while loop if both pointers i and j are less than the length of the left and right lists\n",
    "    while i < len(left) and j < len(right):\n",
    "        # Compare the elements at every position of both lists during each iteration\n",
    "        if left[i] < right[j]:\n",
    "            # output is populated with the lesser value\n",
    "            output.append(left[i])\n",
    "            # 10. Move pointer to the right\n",
    "            i += 1\n",
    "        else:\n",
    "            output.append(right[j])\n",
    "            j += 1\n",
    "    # The remnant elements are picked from the current pointer value to the end of the respective list\n",
    "    output.extend(left[i:])\n",
    "    output.extend(right[j:])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "slice = builtins.slice\n",
    "\n",
    "class Range(namedtuple('RangeBase', 'start,end')):\n",
    "    \n",
    "    def intersects(self, other):\n",
    "        return (\n",
    "            (self.end >= other.end) and (self.start < other.end) or\n",
    "            (self.end >= other.start) and (self.start < other.start) or\n",
    "            (self.end < other.end) and (self.start >= other.start)\n",
    "        )\n",
    "    \n",
    "    def precedes(self, other):\n",
    "        return self.end < other.start\n",
    "    \n",
    "    def to_slice(self):\n",
    "        return slice(*map(int, self)) # maps whole tuple set\n",
    "    \n",
    "\n",
    "\n",
    "def ranges_of(array):\n",
    "    marks = np.logical_xor(array[1:], array[:-1])\n",
    "    boundaries = np.hstack((np.zeros(1), np.where(marks != 0)[0], np.zeros(1) + len(array) - 1))\n",
    "\n",
    "    if not array[0]:\n",
    "        boundaries = boundaries[1:]\n",
    "    if len(boundaries) % 2 != 0:\n",
    "        boundaries = boundaries[:-1]\n",
    "    return tuple(Range(*boundaries[i:i+2]) for i in range(0, len(boundaries), 2))\n",
    "\n",
    "\n",
    "def intersections(left, right):\n",
    "    i, j = 0, 0\n",
    "    result = []\n",
    "    while i < len(left) and j < len(right):\n",
    "        lelt, relt = left[i], right[j]\n",
    "        if lelt.intersects(relt):\n",
    "            result.append(lelt)\n",
    "            i += 1\n",
    "        elif relt.precedes(lelt):\n",
    "            j += 1\n",
    "        elif lelt.precedes(relt):\n",
    "            i += 1\n",
    "    return result\n",
    "\n",
    "\n",
    "hi = np.array(hf.zero_one_for_jumps_base(rms_rolled, high_decision_cutoff))\n",
    "lo = np.array(hf.zero_one_for_jumps_base(rms_rolled, decision_cutoff))\n",
    "\n",
    "rhi = ranges_of(hi)\n",
    "rlo = ranges_of(lo)\n",
    "\n",
    "keep = intersections(rlo, rhi)\n",
    "\n",
    "\n",
    "points = np.array(sum(keep, start=()), dtype=np.int32)\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seven_line = np.zeros(len(rms_rolled))\n",
    "for seven_range in keep:\n",
    "    seven_line[seven_range.to_slice()] = 7\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff),  color = 'green')\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],(np.array(hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff)))*2, color= 'purple')\n",
    "    #plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))], six_line)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))], seven_line)\n",
    "else:\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],processed_data_emg[int(start_s):(int(start_s) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff),  color = 'green')\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))],(np.array(hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff)))*2, color= 'purple')\n",
    "    #plt.plot(converted_tosecondss[int(star_st):(int(star_st) + len(rms_rolled))], six_line)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s) + len(rms_rolled))], seven_line)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So above our 'seven-line' represents picking based on finding areas with 90% max entropy, then picking evything around them with over 50% entropy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What happened in these breaths?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know the area under the curve for each breath- then the area to where we cross back over 70% of peak values- but should we look at entropy directly- question for Eline. Let's start with breaking the segments into breath or not breath segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our_emg_array = processed_data_emg[int(start):(int(start) + len(rms_rolled))]\n",
    "# jump_indeces = []\n",
    "# zippy = zip(seven_line,seven_line[1:])\n",
    "# for val in enumerate(zippy):\n",
    "#     if val[1][0] != val[1][1]:\n",
    "#         print(val[0])\n",
    "#         jump_indeces.append(val[0])\n",
    "\n",
    "# grouped = np.split(our_emg_array, jump_indeces)\n",
    "# grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to figure out which elements of grouped are breath parts, and make arrays of just those."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so grouped needs to be picked down to where at jump indeces we go up from 0 to 7\n",
    "our_emg_array_samples = processed_data_emg[int(start):(int(start) + len(rms_rolled))]\n",
    "our_emg_array_seconds = processed_data_emg[int(start_s):(int(start_s) + len(rms_rolled))]\n",
    "zippy = zip(seven_line,seven_line[1:])\n",
    "breath_indeces = []\n",
    "for val in enumerate(zippy):\n",
    "    if val[1][0] < val[1][1]:\n",
    "        print(val[0])\n",
    "        breath_indeces.append(val[0])\n",
    "if time_view == 'Samples':\n",
    "    grouped_breaths = np.split(our_emg_array_samples, breath_indeces)\n",
    "    grouped_entropy= np.split(rms_rolled, breath_indeces)\n",
    "\n",
    "else:\n",
    "    grouped_breaths = np.split(our_emg_array_seconds, breath_indeces)\n",
    "    grouped_entropy= np.split(rms_rolled, breath_indeces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for group in grouped_breaths:\n",
    "    group = abs(group)\n",
    "    plt.plot(group, alpha = 0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "for group in grouped_entropy:\n",
    "     plt.plot(group, alpha = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# now for each breath started segment get the \"outside peak envelope\", smooth it, and get the area under the curve until we reach 70%\n",
    "The first cell below is an examiner where we plot out the absolute value on each breath group to make sure we are catching breaths."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot out the smoothed breaths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in grouped_breaths:\n",
    "    group = abs(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "plt.plot(abs(grouped_breaths[3]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = abs(grouped_breaths[3])\n",
    "\n",
    "peaks, _ = find_peaks(x, distance =len(x)/50,  height=0)\n",
    "\n",
    "plt.plot(x)\n",
    "\n",
    "plt.plot(peaks, x[peaks], \"x\")\n",
    "\n",
    "plt.plot(np.zeros_like(x), \"--\", color=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def hi_envelope(signal, dmax=24):\n",
    "    \"\"\"\n",
    "    Takes a 1d signal array, and extracts 'high'envelope, then makes high envelope\n",
    "    dmax: int, ize of chunks, \n",
    "    \n",
    "    \"\"\"\n",
    "    # locals max\n",
    "    lmax = (np.diff(np.sign(np.diff(signal))) < 0).nonzero()[0] + 1 \n",
    "    lmax = lmax[[i+np.argmax(s[lmax[i:i+dmax]]) for i in range(0,len(lmax),dmax)]]\n",
    "    smoothed = savgol_filter(signal[high_idx] , int(0.8* (len(high_idx ))), 3)\n",
    "    smoothed_interped = scipy.signal.resample(smoothed, len(signal))\n",
    "    return smoothed_interped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed = savgol_filter(signal[high_idx] , int(0.8* (len(high_idx ))), 3)\n",
    "smoothed_interped = scipy.signal.resample(smoothed, len(grouped_breaths[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(high_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smoothed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(smoothed_interped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,len(grouped_breaths[3]),len(grouped_breaths[3]))\n",
    "s = abs(grouped_breaths[3])\n",
    "#high_idx, low_idx = hl_envelopes_idx(s)\n",
    "\n",
    "# high_idx = hi_envelope_points(s,dmax=24)\n",
    "# smoothed = savgol_filter(s[high_idx] , int(0.8* (len(high_idx ))), 3)\n",
    "# smoothed_interped = scipy.signal.resample(smoothed, len(grouped_breaths[3]))\n",
    "smoothed_i = hi_envelope(s,dmax=24)\n",
    "# plot\n",
    "plt.plot(t,s,label='signal')\n",
    "#plt.plot(t[high_idx],s[high_idx], 'r', label='low')\n",
    "plt.plot(t,smoothed_i, 'g', label='high')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.linspace(0,8*np.pi,5000)\n",
    "s = 0.8*np.cos(t)**3 + 0.5*np.sin(np.exp(1)*t)\n",
    "high_idx, low_idx = hl_envelopes_idx(s)\n",
    "\n",
    "# plot\n",
    "plt.plot(t,s,label='signal')\n",
    "plt.plot(t[high_idx], s[high_idx], 'r', label='low')\n",
    "plt.plot(t[low_idx], s[low_idx], 'g', label='high')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_breaths = []\n",
    "for group in grouped_breaths:\n",
    "    group = abs(group)\n",
    "    smoothed = savgol_filter(group, int(0.8* (len(group))), 3)\n",
    "    plt.plot(smoothed)\n",
    "    smoothed_breaths.append(smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot out smoothed entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_breaths_entropy = []\n",
    "for group in grouped_entropy:\n",
    "    smoothed = savgol_filter(group, int(0.8* (len(group))), 3)\n",
    "    plt.plot(smoothed)\n",
    "    smoothed_breaths_entropy.append(smoothed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the area under the curve until the curve of the breath passes it's maximum then hits 70% of it's peak value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_area_under = []\n",
    "for curve in smoothed_breaths:\n",
    "    max_ind = (curve.argmax())\n",
    "    max_val = curve[max_ind]\n",
    "    absolute_val_array = np.abs(curve[max_ind:] - curve.max() * 0.7)\n",
    "    smallest_difference_index = absolute_val_array.argmin()\n",
    "    closest_element = curve[max_ind:][smallest_difference_index]\n",
    "    smallest_difference_index = smallest_difference_index + max_ind\n",
    "    area_under_curve_cut = curve[:smallest_difference_index].sum()\n",
    "    curve_area_under.append(area_under_curve_cut)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the future function pending eline approval \n",
    "def breath_curve_catch(curve):\n",
    "    \"\"\"\n",
    "    The function is intended for smoothed arrays\n",
    "    The function takes a smoothed breath array then calculates part of the area under the curve \n",
    "    including up to the peak and then to 70% of the peak valye\n",
    "    \"\"\"\n",
    "    max_ind = (curve.argmax())\n",
    "    max_val = curve[max_ind]\n",
    "    absolute_val_array = np.abs(curve[max_ind:] - curve.max() * 0.7)\n",
    "    smallest_difference_index = absolute_val_array.argmin()\n",
    "    closest_element = curve[max_ind:][smallest_difference_index]\n",
    "    smallest_difference_index = smallest_difference_index + max_ind\n",
    "    area_under_curve_cut = curve[:smallest_difference_index].sum()\n",
    "    return area_under_curve_cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we have an array with all of those areas (to 70% of curve ) for each smoothed breath\n",
    "curve_area_under"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK, but what area these areas? let's see an example of what curve it cuts then takes the area under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numbers_to_show = []\n",
    "for i in range(len(smoothed_breaths)):\n",
    "    list_of_numbers_to_show.append(str(i))\n",
    "\n",
    "\n",
    "breath_to_show = widgets.Dropdown(\n",
    "    options=list_of_numbers_to_show,\n",
    "    value='1',\n",
    "    description='Picked Breaths:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(breath_to_show)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's show an example with a graph to show how it looks\n",
    "curve_example = smoothed_breaths[int(breath_to_show.value)]\n",
    "max_ind = (curve_example.argmax())\n",
    "max_val =  curve_example[max_ind]\n",
    "absolute_val_array = np.abs(curve_example[max_ind:] - curve.max() * 0.7)\n",
    "smallest_difference_index = absolute_val_array.argmin()\n",
    "closest_element = curve_example[max_ind:][smallest_difference_index]\n",
    "smallest_difference_index = smallest_difference_index + max_ind\n",
    "area_under_curve_cut = curve_example[:smallest_difference_index].sum()\n",
    "plt.plot(curve_example, color= 'purple', alpha = 0.7)\n",
    "plt.plot(curve_example[:smallest_difference_index],color = 'green', alpha = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But what if we want to cut on 70% entropy past the peak instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_area_under_entropy = []\n",
    "\n",
    "for i, entropy_curve in enumerate(smoothed_breaths_entropy):\n",
    "    max_ind = (entropy_curve.argmax())\n",
    "    max_val = entropy_curve[max_ind]\n",
    "    absolute_val_array = np.abs(entropy_curve[max_ind:] - entropy_curve.max() * 0.7)\n",
    "    smallest_difference_index = absolute_val_array.argmin()\n",
    "    closest_element = entropy_curve[max_ind:][smallest_difference_index]\n",
    "    smallest_difference_index = smallest_difference_index + max_ind\n",
    "    area_under_curve_cut = smoothed_breaths[i][:smallest_difference_index].sum()\n",
    "    curve_area_under_entropy.append(area_under_curve_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curve_area_under_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "our_emg_array = processed_data_emg[int(start):(int(start) + len(rms_rolled))]\n",
    "our_entropy_array = rms_rolled\n",
    "zippy = zip(seven_line,seven_line[1:])\n",
    "breath_indeces = []\n",
    "for val in enumerate(zippy):\n",
    "    if val[1][0] < val[1][1]:\n",
    "        print(val[0])\n",
    "        breath_indeces.append(val[0])\n",
    "\n",
    "grouped_breaths = np.split(our_emg_array, breath_indeces)\n",
    "grouped_entropy= np.split(rms_rolled, breath_indeces)\n",
    "grouped_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So great, we can do it, however we have to agree that the amount of smoothing to calculate these things is acceptable, and whether we use the entropy or the EMG itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We also need to agree on what other data is collected into the final spreadsheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we can compare counted 'breaths' to algorithm breaths, then we can compare a sequence of peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_count = input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare our peak value sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Also we are looking at distance from zero to positive maxima, but the amplitude would be from adjancent low value...\n",
    "We can look at an absolute value array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_maxima_in_high_entropy_area(our_array,start=0, end=10000, decision_cutoff='mean'):\n",
    "    \"\"\"\n",
    "    Finds maxima in high entropy areas. You need to have made an rms_rolled variable\n",
    "    on the entropy areas.\n",
    "    The function is not yet optimized, but works here in the notebook. \n",
    "    \"\"\"\n",
    " \n",
    "    #rms_rolled= \n",
    "    decision_array = hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff)\n",
    "    if decision_array[0] == 1:\n",
    "        ups_and_downs = np.logical_xor(decision_array[1:], decision_array[:-1])\n",
    "        indeces_of_boundaries = np.where(ups_and_downs)[0]\n",
    "        maxima = []\n",
    "        boundaries = np.append(\n",
    "            np.append(np.zeros(1), indeces_of_boundaries),\n",
    "            np.zeros(1) + len(our_array),\n",
    "        )\n",
    "        # print(boundaries)\n",
    "        boundaries = boundaries.astype(np.int32)\n",
    "        for slice_start, slice_end in zip(boundaries[::2], boundaries[1::2]):\n",
    "            #print(slice_start, slice_end)\n",
    "            beat = our_array[slice_start:slice_end]\n",
    "            maxima.append(slice_start + np.where(beat == beat.max())[0][0])\n",
    "        maxima_values = our_array[maxima]\n",
    "        # print(maxima_values)\n",
    "        rep_array = np.zeros(len(our_array))\n",
    "        rep_array[maxima] = np.mean(maxima_values)\n",
    "        plt.plot(our_array, alpha = 0.7)\n",
    "        plt.plot(rep_array, alpha = 0.4)\n",
    "    else: \n",
    "        ups_and_downs = np.logical_xor(decision_array[1:], decision_array[:-1])\n",
    "        indeces_of_boundaries = np.where(ups_and_downs)[0]\n",
    "        maxima = []\n",
    "        boundaries = np.append(\n",
    "            indeces_of_boundaries,\n",
    "            np.zeros(1) + len(our_array),\n",
    "        )\n",
    "        boundaries = boundaries.astype(np.int32)\n",
    "        for slice_start, slice_end in zip(boundaries[::2], boundaries[1::2]):\n",
    "            #print(slice_start, slice_end)\n",
    "            beat = our_array[slice_start:slice_end]\n",
    "            maxima.append(slice_start + np.where(beat == beat.max())[0][0])\n",
    "        maxima_values = our_array[maxima]\n",
    "        #print(maxima_values)\n",
    "        rep_array = np.zeros(len(our_array))\n",
    "        rep_array[maxima] = np.mean(maxima_values)\n",
    "        plt.plot(our_array, alpha = 0.7)\n",
    "        plt.plot(rep_array, alpha = 0.4)\n",
    "    return maxima, maxima_values\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_view == 'Samples':\n",
    "    our_array = processed_data_emg[int(start):int(end)]\n",
    "    starter=int(start)\n",
    "    ender= int(end)\n",
    "else: \n",
    "    our_array = processed_data_emg[int(start_s):int(end_s)]\n",
    "    starter=int(start_s)\n",
    "    ender= int(end_s)\n",
    "\n",
    "maximal , maximal_values = find_maxima_in_high_entropy_area(our_array,start=starter, end=ender, decision_cutoff=decision_cutoff)\n",
    "# note the x axis will be from zero counting up but represent the difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several decisions that need to be made here. Note the following:\n",
    "    \n",
    "    We are looking at maxima on the positive. Maybe we should be looking on both sides of zero? Maybe we should be lokking at an absolute value, and then find the maxima? Also note our cut-off on entropy was a bit arbitraty, and gave us an extra breath. These are decisions for the scientific side of a team that need to happen before this interface can go furhter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we have to decide if we do area under curve for the absolute value, or what?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now I can save off the info on this run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_now = [file_chosen, number_chosen, time_view, start, end, my_count, max_per_peak_count, maximal, maximal_values, curve_area_under]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_data_list.append(data_now)\n",
    "big_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_now = ['file_chosen',\n",
    "               'number_file',\n",
    "               'units',\n",
    "               'start_cut',\n",
    "               'end_cut',\n",
    "               'my_hand_count',\n",
    "               'automated_breath_count',\n",
    "               'maxima',\n",
    "               'maxima_values',\n",
    "               'curve_area_under',\n",
    "               'curve_area_under_entropy',\n",
    "               ]\n",
    "\n",
    "df = pd.DataFrame(big_data_list, columns=columns_now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You probably want to change the name to a timestamp, and save every hour, at least. \n",
    "df.to_csv('my_saved_entropy_experiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
