{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warning\n",
    "This notebook is under development- please use to evaluate entropy algorithms, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments on entropy implementation towards speed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import find_peaks\n",
    "import collections\n",
    "import math\n",
    "from scipy.stats import entropy\n",
    "from math import log, e\n",
    "\n",
    "\n",
    "from resurfemg.tmsisdk_lite import Poly5Reader\n",
    "from resurfemg.config import Config\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set a collection place for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pull local helper functions\n",
    "sys.path.insert(0, '../resurfemg')\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# do not rerun this cell\n",
    "big_data_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below change the path to the root directory where you are keeping your EMGs and ventilator \"Draeger\" files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reruns should be done from this cell as the start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_emg_directory = config.get_directory('root_emg_directory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_draeger_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "draeger_files = []\n",
    "\n",
    "for file in emg_and_draeger_files:\n",
    "    if 'Draeger' in file:\n",
    "        draeger_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can pick a file from the list, which have been numbered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numbers_strung = []\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_strung.append(str(i))\n",
    "\n",
    "\n",
    "btn = widgets.Dropdown(\n",
    "    options=list_of_numbers_strung,\n",
    "    value='0',\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_chosen = int(btn.value)\n",
    "file_chosen = emg_files[number_chosen] \n",
    "print(\"The file you chose is:\", file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emg = Poly5Reader(file_chosen)\n",
    "data_samples = data_emg.samples\n",
    "emg_sample_rate = data_emg.sample_rate\n",
    "converted_to_seconds =  []\n",
    "converted_to_samples = []\n",
    "for i in range(len(data_samples[0])):\n",
    "    converted_to_seconds.append(i/emg_sample_rate)\n",
    "    converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = data_samples\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 2, figsize=(6, 6))\n",
    "#ax.set_ylim([-4, 4])\n",
    "axis[0,0].grid(True)\n",
    "axis[0,0].plot(x[0])\n",
    "axis[0,0].set(title='leads in samples')\n",
    "axis[1,0].plot(x[1])\n",
    "axis[2,0].plot(x[2])\n",
    "axis[0,1].set(title='leads in seconds')\n",
    "axis[0,1].grid(True)\n",
    "axis[0,1].plot(converted_to_seconds,x[0])\n",
    "axis[1,1].plot(converted_to_seconds,x[1])\n",
    "axis[2,1].plot(converted_to_seconds,x[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is the whole unfiltered EMG, but you probably want to examine a part. You will also want to examine something filtered down to only the EMG components. Therefore we will filter off only the EMG components with an ICA in addtion to the filter we will play with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can filter down to which part you want to see. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you want to cut and see the file in samples or seconds?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_axis = widgets.Dropdown(\n",
    "    options=[\"Samples\",\"Seconds\"],\n",
    "    value='Samples',\n",
    "    description=\"Select View Option\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(y_axis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_view= y_axis.value\n",
    "time_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type in start number and press return for it to update\n",
    "start = input()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type in end number and press return for it to update\n",
    "end= input()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Do we want to?\n",
    "# Add warning cell if end is less than start, or numbers are out of range?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_s = float(start)* emg_sample_rate\n",
    "end_s = float(end)*emg_sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if time_view == 'Samples':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x = data_samples\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(x[0][int(start):int(end)])\n",
    "    ax_1.set(title='leads, samples')\n",
    "    ax_2.plot(x[1][int(start):int(end)])\n",
    "    ax_3.plot(x[2][int(start):int(end)])\n",
    "    \n",
    "if time_view == 'Seconds':\n",
    "    # nox examine at a certain scale- from point a to b as samples\n",
    "    x_for_secs = data_samples\n",
    "    \n",
    "    converter_for_sample_number =90\n",
    "    \n",
    "    y = converted_to_seconds\n",
    "    fig, (ax_1,ax_2,ax_3) = plt.subplots(nrows = 3, figsize=(6, 4))\n",
    "    ax_1.grid(True)\n",
    "    ax_1.plot(y[int(start_s):int(end_s)],x[0][int(start_s):int(end_s)])\n",
    "    ax_1.set(title='leads, seconds')\n",
    "    ax_2.plot(y[int(start_s):int(end_s)],x[1][int(start_s):int(end_s)])\n",
    "    ax_3.plot(y[int(start_s):int(end_s)],x[2][int(start_s):int(end_s)])\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Happy with your selection? If not redo, then we can see how the filter the selection in a basic pipleline before extracint entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def working_pipeline_pre_entropy(our_chosen_samples): \n",
    "    cut_file_data = hf.bad_end_cutter_for_samples(our_chosen_samples, percent_to_cut=3, tolerance_percent=5)\n",
    "    bd_filtered_file_data = hf.emg_bandpass_butter_sample(cut_file_data, 5, 450, 2048, output='sos')\n",
    "    # step 3 end-cutting again to get rid of filtering artifacts\n",
    "    re_cut_file_data = hf.bad_end_cutter_for_samples(bd_filtered_file_data, percent_to_cut=3, tolerance_percent=5)\n",
    "    # skip step4 and do step 5 ICA\n",
    "    components = hf.compute_ICA_two_comp(re_cut_file_data)\n",
    "    #     the picking step!\n",
    "    emg= hf.pick_more_peaks_array(components)\n",
    "    # now process it in final steps\n",
    "    abs_values = abs(emg)\n",
    "    final_envelope_d = hf.emg_highpass_butter(abs_values, 150, 2048)\n",
    "    \n",
    "        \n",
    "    return final_envelope_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data_emg = working_pipeline_pre_entropy(data_samples)\n",
    "plt.plot(processed_data_emg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def entropy_scipy(sli, base=None):\n",
    "    \"\"\"\n",
    "    This function wraps scipy.stats entropy for use in the resurfemg library, it can be\n",
    "    used in a slice iterator as a drop-in substitute for the hf.entropical\n",
    "    except it is a true entropy.\n",
    "    \n",
    "    returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    value,counts = np.unique(sli, return_counts=True)\n",
    "    entropy_count = entropy(counts, base=base)\n",
    "    return entropy_count\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sampen(data, emb_dim=2, tolerance=None, dist=rowwise_chebyshev,\n",
    "           closed=False, debug_plot=False, debug_data=False, plot_file=None):\n",
    "  \"\"\"\n",
    "  The following code is adapted from openly licensed code written by \n",
    "  Christopher Schölzel in his package nolds (NOnLinear measures for Dynamical Systems). \n",
    "  It computes the sample entropy of time sequence data.\n",
    "  \n",
    "  Reference:\n",
    "    .. [se_1] J. S. Richman and J. R. Moorman, “Physiological time-series\n",
    "       analysis using approximate entropy and sample entropy,”\n",
    "       American Journal of Physiology-Heart and Circulatory Physiology,\n",
    "       vol. 278, no. 6, pp. H2039–H2049, 2000.\n",
    "\n",
    "  Args:\n",
    "    data (array-like of float):\n",
    "      input data\n",
    "  Kwargs:\n",
    "    emb_dim (int):\n",
    "      the embedding dimension (length of vectors to compare)\n",
    "    tolerance (float):\n",
    "      distance threshold for two template vectors to be considered equal\n",
    "      (default: 0.2 * std(data) at emb_dim = 2, corrected for dimension effect\n",
    "      for other values of emb_dim)\n",
    "    dist (function (2d-array, 1d-array) -> 1d-array):\n",
    "      distance function used to calculate the distance between template\n",
    "      vectors. Sampen is defined using ``rowwise_chebyshev``. You should only\n",
    "      use something else, if you are sure that you need it.\n",
    "    closed (boolean):\n",
    "      if True, will check for vector pairs whose distance is in the closed\n",
    "      interval [0, r] (less or equal to r), otherwise the open interval\n",
    "      [0, r) (less than r) will be used\n",
    "    debug_plot (boolean):\n",
    "      if True, a histogram of the individual distances for m and m+1\n",
    "    debug_data (boolean):\n",
    "      if True, debugging data will be returned alongside the result\n",
    "    plot_file (str):\n",
    "      if debug_plot is True and plot_file is not None, the plot will be saved\n",
    "      under the given file name instead of directly showing it through\n",
    "      ``plt.show()``\n",
    "  Returns:\n",
    "    float:\n",
    "      the sample entropy of the data (negative logarithm of ratio between\n",
    "      similar template vectors of length emb_dim + 1 and emb_dim)\n",
    "    [c_m, c_m1]:\n",
    "      list of two floats: count of similar template vectors of length emb_dim\n",
    "      (c_m) and of length emb_dim + 1 (c_m1)\n",
    "    [float list, float list]:\n",
    "      Lists of lists of the form ``[dists_m, dists_m1]`` containing the\n",
    "      distances between template vectors for m (dists_m)\n",
    "      and for m + 1 (dists_m1).\n",
    "  \"\"\"\n",
    "  data = np.asarray(data)\n",
    "\n",
    "  if tolerance is None:\n",
    "\n",
    "    tolerance = np.std(data, ddof=1) * 0.1164 * (0.5627 * np.log(emb_dim) + 1.3334)\n",
    "  n = len(data)\n",
    "\n",
    "  # build matrix of \"template vectors\"\n",
    "  # (all consecutive subsequences of length m)\n",
    "  # x0 x1 x2 x3 ... xm-1\n",
    "  # x1 x2 x3 x4 ... xm\n",
    "  # x2 x3 x4 x5 ... xm+1\n",
    "  # ...\n",
    "  # x_n-m-1     ... xn-1\n",
    "\n",
    "  # since we need two of these matrices for m = emb_dim and m = emb_dim +1,\n",
    "  # we build one that is large enough => shape (emb_dim+1, n-emb_dim)\n",
    "\n",
    "  # note that we ignore the last possible template vector with length emb_dim,\n",
    "  # because this vector has no corresponding vector of length m+1 and thus does\n",
    "  # not count towards the conditional probability\n",
    "  # (otherwise first dimension would be n-emb_dim+1 and not n-emb_dim)\n",
    "  tVecs = delay_embedding(np.asarray(data), emb_dim+1, lag=1)\n",
    "  plot_data = []\n",
    "  counts = []\n",
    "  for m in [emb_dim, emb_dim + 1]:\n",
    "    counts.append(0)\n",
    "    plot_data.append([])\n",
    "    # get the matrix that we need for the current m\n",
    "    tVecsM = tVecs[:n - m + 1, :m]\n",
    "    # successively calculate distances between each pair of template vectors\n",
    "    for i in range(len(tVecsM) - 1):\n",
    "      dsts = dist(tVecsM[i + 1:], tVecsM[i])\n",
    "      if debug_plot or debug_data:\n",
    "        plot_data[-1].extend(dsts)\n",
    "      # count how many distances are smaller than the tolerance\n",
    "      if closed:\n",
    "        counts[-1] += np.sum(dsts <= tolerance)\n",
    "      else:\n",
    "        counts[-1] += np.sum(dsts < tolerance)\n",
    "  if counts[0] > 0 and counts[1] > 0:\n",
    "    saen = -np.log(1.0 * counts[1] / counts[0])\n",
    "  else:\n",
    "    # log would be infinite or undefined => cannot determine saen\n",
    "    zcounts = []\n",
    "    if counts[0] == 0:\n",
    "      zcounts.append(\"emb_dim\")\n",
    "    if counts[1] == 0:\n",
    "      zcounts.append(\"emb_dim + 1\")\n",
    "    warnings.warn(\n",
    "      (\n",
    "        \"Zero vectors are within tolerance for %s. \" \\\n",
    "        + \"Consider raising the tolerance parameter to avoid %s result.\"\n",
    "      ) % (\" and \".join(zcounts), \"NaN\" if len(zcounts) == 2 else \"inf\"),\n",
    "      RuntimeWarning\n",
    "    )\n",
    "    if counts[0] == 0 and counts[1] == 0:\n",
    "      saen = np.nan\n",
    "    elif counts[0] == 0:\n",
    "      saen = -np.inf\n",
    "    else:\n",
    "      saen = np.inf\n",
    "  if debug_plot:\n",
    "    plot_dists(plot_data, tolerance, m, title=\"sampEn = {:.3f}\".format(saen),\n",
    "               fname=plot_file)\n",
    "  if debug_data:\n",
    "    return (saen, counts, plot_data)\n",
    "  else:\n",
    "    return saen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sampen2(data, emb_dim=2, tolerance=None, dist=rowwise_chebyshev,\n",
    "           closed=False ):#, debug_plot=False, debug_data=False, plot_file=None):\n",
    "  \"\"\"\n",
    "  The following code is adapted from openly licensed code written by \n",
    "  Christopher Schölzel in his package nolds (NOnLinear measures for Dynamical Systems). \n",
    "  It computes the sample entropy of time sequence data.\n",
    "  \n",
    "  Reference:\n",
    "    .. [se_1] J. S. Richman and J. R. Moorman, “Physiological time-series\n",
    "       analysis using approximate entropy and sample entropy,”\n",
    "       American Journal of Physiology-Heart and Circulatory Physiology,\n",
    "       vol. 278, no. 6, pp. H2039–H2049, 2000.\n",
    "\n",
    "  Args:\n",
    "    data (array-like of float):\n",
    "      input data\n",
    "  Kwargs:\n",
    "    emb_dim (int):\n",
    "      the embedding dimension (length of vectors to compare)\n",
    "    tolerance (float):\n",
    "      distance threshold for two template vectors to be considered equal\n",
    "      (default: 0.2 * std(data) at emb_dim = 2, corrected for dimension effect\n",
    "      for other values of emb_dim)\n",
    "    dist (function (2d-array, 1d-array) -> 1d-array):\n",
    "      distance function used to calculate the distance between template\n",
    "      vectors. Sampen is defined using ``rowwise_chebyshev``. You should only\n",
    "      use something else, if you are sure that you need it.\n",
    "    closed (boolean):\n",
    "      if True, will check for vector pairs whose distance is in the closed\n",
    "      interval [0, r] (less or equal to r), otherwise the open interval\n",
    "      [0, r) (less than r) will be used\n",
    "    debug_plot (boolean):\n",
    "      if True, a histogram of the individual distances for m and m+1\n",
    "    debug_data (boolean):\n",
    "      if True, debugging data will be returned alongside the result\n",
    "    plot_file (str):\n",
    "      if debug_plot is True and plot_file is not None, the plot will be saved\n",
    "      under the given file name instead of directly showing it through\n",
    "      ``plt.show()``\n",
    "  Returns:\n",
    "    float:\n",
    "      the sample entropy of the data (negative logarithm of ratio between\n",
    "      similar template vectors of length emb_dim + 1 and emb_dim)\n",
    "    [c_m, c_m1]:\n",
    "      list of two floats: count of similar template vectors of length emb_dim\n",
    "      (c_m) and of length emb_dim + 1 (c_m1)\n",
    "    [float list, float list]:\n",
    "      Lists of lists of the form ``[dists_m, dists_m1]`` containing the\n",
    "      distances between template vectors for m (dists_m)\n",
    "      and for m + 1 (dists_m1).\n",
    "  \"\"\"\n",
    "  data = np.asarray(data)\n",
    "\n",
    "  if tolerance is None:\n",
    "\n",
    "    tolerance = np.std(data, ddof=1) * 0.1164 * (0.5627 * np.log(emb_dim) + 1.3334)\n",
    "  n = len(data)\n",
    "\n",
    "  # build matrix of \"template vectors\"\n",
    "  # (all consecutive subsequences of length m)\n",
    "  # x0 x1 x2 x3 ... xm-1\n",
    "  # x1 x2 x3 x4 ... xm\n",
    "  # x2 x3 x4 x5 ... xm+1\n",
    "  # ...\n",
    "  # x_n-m-1     ... xn-1\n",
    "\n",
    "  # since we need two of these matrices for m = emb_dim and m = emb_dim +1,\n",
    "  # we build one that is large enough => shape (emb_dim+1, n-emb_dim)\n",
    "\n",
    "  # note that we ignore the last possible template vector with length emb_dim,\n",
    "  # because this vector has no corresponding vector of length m+1 and thus does\n",
    "  # not count towards the conditional probability\n",
    "  # (otherwise first dimension would be n-emb_dim+1 and not n-emb_dim)\n",
    "  tVecs = delay_embedding(np.asarray(data), emb_dim+1, lag=1)\n",
    "  plot_data = []\n",
    "  counts = []\n",
    "  for m in [emb_dim, emb_dim + 1]:\n",
    "    counts.append(0)\n",
    "    plot_data.append([])\n",
    "    # get the matrix that we need for the current m\n",
    "    tVecsM = tVecs[:n - m + 1, :m]\n",
    "    # successively calculate distances between each pair of template vectors\n",
    "    for i in range(len(tVecsM) - 1):\n",
    "      dsts = dist(tVecsM[i + 1:], tVecsM[i])\n",
    "#       if debug_plot or debug_data:\n",
    "#         plot_data[-1].extend(dsts)\n",
    "      # count how many distances are smaller than the tolerance\n",
    "      if closed:\n",
    "        counts[-1] += np.sum(dsts <= tolerance)\n",
    "      else:\n",
    "        counts[-1] += np.sum(dsts < tolerance)\n",
    "  if counts[0] > 0 and counts[1] > 0:\n",
    "    saen = -np.log(1.0 * counts[1] / counts[0])\n",
    "  else:\n",
    "    # log would be infinite or undefined => cannot determine saen\n",
    "    zcounts = []\n",
    "    if counts[0] == 0:\n",
    "      zcounts.append(\"emb_dim\")\n",
    "    if counts[1] == 0:\n",
    "      zcounts.append(\"emb_dim + 1\")\n",
    "    warnings.warn(\n",
    "      (\n",
    "        \"Zero vectors are within tolerance for %s. \" \\\n",
    "        + \"Consider raising the tolerance parameter to avoid %s result.\"\n",
    "      ) % (\" and \".join(zcounts), \"NaN\" if len(zcounts) == 2 else \"inf\"),\n",
    "      RuntimeWarning\n",
    "    )\n",
    "    if counts[0] == 0 and counts[1] == 0:\n",
    "      saen = np.nan\n",
    "    elif counts[0] == 0:\n",
    "      saen = -np.inf\n",
    "    else:\n",
    "      saen = np.inf\n",
    "#   if debug_plot:\n",
    "#     plot_dists(plot_data, tolerance, m, title=\"sampEn = {:.3f}\".format(saen),\n",
    "#                fname=plot_file)\n",
    "#   if debug_data:\n",
    "#     return (saen, counts, plot_data)\n",
    "#   else:\n",
    "    return saen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rowwise_chebyshev(x, y):\n",
    "  return np.max(np.abs(x - y), axis=1)\n",
    "\n",
    "def delay_embedding(data, emb_dim, lag=1):\n",
    "  \"\"\"\n",
    "  The following code is adapted from openly licensed code written by \n",
    "  Christopher Schölzel in his package nolds (NOnLinear measures for Dynamical Systems). \n",
    "  It performs a time-delay embedding of a time series\n",
    "  \n",
    "  :param data: array-like\n",
    "  :type data: array\n",
    "  :param emb_dim: the embedded dimension\n",
    "  :type emb_dim: int\n",
    "  :param lag: the lag between elements in the embedded vectors\n",
    "  :type lag: int\n",
    "  \n",
    "  :returns: matrix_vectors\n",
    "  :rtype: ~nd.array\n",
    "  \"\"\"\n",
    "  data = np.asarray(data)\n",
    "  min_len = (emb_dim - 1) * lag + 1\n",
    "  if len(data) < min_len:\n",
    "    msg = \"cannot embed data of length {} with embedding dimension {} \" \\\n",
    "        + \"and lag {}, minimum required length is {}\"\n",
    "    raise ValueError(msg.format(len(data), emb_dim, lag, min_len))\n",
    "  m = len(data) - min_len + 1\n",
    "  indices = np.repeat([np.arange(emb_dim) * lag], m, axis=0)\n",
    "  indices += np.arange(m).reshape((m, 1))\n",
    "  matrix_vectors = data[indices]\n",
    "  return matrix_vectors\n",
    "\n",
    "\n",
    "\n",
    "def sampen(data, emb_dim=2, tolerance=None, dist=rowwise_chebyshev,\n",
    "           closed=False, debug_plot=False, debug_data=False, plot_file=None):\n",
    "  \"\"\"\n",
    "  The following code is adapted from openly licensed code written by \n",
    "  Christopher Schölzel in his package nolds (NOnLinear measures for Dynamical Systems). \n",
    "  It computes the sample entropy of time sequence data.\n",
    "  \n",
    "  Reference:\n",
    "    .. [se_1] J. S. Richman and J. R. Moorman, “Physiological time-series\n",
    "       analysis using approximate entropy and sample entropy,”\n",
    "       American Journal of Physiology-Heart and Circulatory Physiology,\n",
    "       vol. 278, no. 6, pp. H2039–H2049, 2000.\n",
    "    \n",
    "  Args:\n",
    "    data (array-like of float):\n",
    "      input data\n",
    "  Kwargs:\n",
    "    emb_dim (int):\n",
    "      the embedding dimension (length of vectors to compare)\n",
    "    tolerance (float):\n",
    "      distance threshold for two template vectors to be considered equal\n",
    "      (default: 0.2 * std(data) at emb_dim = 2, corrected for dimension effect\n",
    "      for other values of emb_dim)\n",
    "    dist (function (2d-array, 1d-array) -> 1d-array):\n",
    "      distance function used to calculate the distance between template\n",
    "      vectors. Sampen is defined using ``rowwise_chebyshev``. You should only\n",
    "      use something else, if you are sure that you need it.\n",
    "    closed (boolean):\n",
    "      if True, will check for vector pairs whose distance is in the closed\n",
    "      interval [0, r] (less or equal to r), otherwise the open interval\n",
    "      [0, r) (less than r) will be used\n",
    "    debug_plot (boolean):\n",
    "      if True, a histogram of the individual distances for m and m+1\n",
    "    debug_data (boolean):\n",
    "      if True, debugging data will be returned alongside the result\n",
    "    plot_file (str):\n",
    "      if debug_plot is True and plot_file is not None, the plot will be saved\n",
    "      under the given file name instead of directly showing it through\n",
    "      ``plt.show()``\n",
    "  Returns:\n",
    "    float:\n",
    "      the sample entropy of the data (negative logarithm of ratio between\n",
    "      similar template vectors of length emb_dim + 1 and emb_dim)\n",
    "    [c_m, c_m1]:\n",
    "      list of two floats: count of similar template vectors of length emb_dim\n",
    "      (c_m) and of length emb_dim + 1 (c_m1)\n",
    "    [float list, float list]:\n",
    "      Lists of lists of the form ``[dists_m, dists_m1]`` containing the\n",
    "      distances between template vectors for m (dists_m)\n",
    "      and for m + 1 (dists_m1).\n",
    "  \"\"\"\n",
    "  data = np.asarray(data)\n",
    "\n",
    "  if tolerance is None:\n",
    "\n",
    "    tolerance = np.std(data, ddof=1) * 0.1164 * (0.5627 * np.log(emb_dim) + 1.3334)\n",
    "  n = len(data)\n",
    "\n",
    "  # build matrix of \"template vectors\"\n",
    "  # (all consecutive subsequences of length m)\n",
    "  # x0 x1 x2 x3 ... xm-1\n",
    "  # x1 x2 x3 x4 ... xm\n",
    "  # x2 x3 x4 x5 ... xm+1\n",
    "  # ...\n",
    "  # x_n-m-1     ... xn-1\n",
    "\n",
    "  # since we need two of these matrices for m = emb_dim and m = emb_dim +1,\n",
    "  # we build one that is large enough => shape (emb_dim+1, n-emb_dim)\n",
    "\n",
    "  # note that we ignore the last possible template vector with length emb_dim,\n",
    "  # because this vector has no corresponding vector of length m+1 and thus does\n",
    "  # not count towards the conditional probability\n",
    "  # (otherwise first dimension would be n-emb_dim+1 and not n-emb_dim)\n",
    "  tVecs = delay_embedding(np.asarray(data), emb_dim+1, lag=1)\n",
    "  plot_data = []\n",
    "  counts = []\n",
    "  for m in [emb_dim, emb_dim + 1]:\n",
    "    counts.append(0)\n",
    "    plot_data.append([])\n",
    "    # get the matrix that we need for the current m\n",
    "    tVecsM = tVecs[:n - m + 1, :m]\n",
    "    # successively calculate distances between each pair of template vectors\n",
    "    for i in range(len(tVecsM) - 1):\n",
    "      dsts = dist(tVecsM[i + 1:], tVecsM[i])\n",
    "      if debug_plot or debug_data:\n",
    "        plot_data[-1].extend(dsts)\n",
    "      # count how many distances are smaller than the tolerance\n",
    "      if closed:\n",
    "        counts[-1] += np.sum(dsts <= tolerance)\n",
    "      else:\n",
    "        counts[-1] += np.sum(dsts < tolerance)\n",
    "  if counts[0] > 0 and counts[1] > 0:\n",
    "    saen = -np.log(1.0 * counts[1] / counts[0])\n",
    "  else:\n",
    "    # log would be infinite or undefined => cannot determine saen\n",
    "    zcounts = []\n",
    "    if counts[0] == 0:\n",
    "      zcounts.append(\"emb_dim\")\n",
    "    if counts[1] == 0:\n",
    "      zcounts.append(\"emb_dim + 1\")\n",
    "    warnings.warn(\n",
    "      (\n",
    "        \"Zero vectors are within tolerance for %s. \" \\\n",
    "        + \"Consider raising the tolerance parameter to avoid %s result.\"\n",
    "      ) % (\" and \".join(zcounts), \"NaN\" if len(zcounts) == 2 else \"inf\"),\n",
    "      RuntimeWarning\n",
    "    )\n",
    "    if counts[0] == 0 and counts[1] == 0:\n",
    "      saen = np.nan\n",
    "    elif counts[0] == 0:\n",
    "      saen = -np.inf\n",
    "    else:\n",
    "      saen = np.inf\n",
    "  if debug_plot:\n",
    "    plot_dists(plot_data, tolerance, m, title=\"sampEn = {:.3f}\".format(saen),\n",
    "               fname=plot_file)\n",
    "  if debug_data:\n",
    "    return (saen, counts, plot_data)\n",
    "  else:\n",
    "    return saen\n",
    "\n",
    "\n",
    "def entropy_maker(array, method='nolds', base=None, emb_dim=2, tolerance=None, dist=rowwise_chebyshev,\n",
    "           closed=False, debug_plot=False, debug_data=False, plot_file=None):\n",
    "    \"\"\"\n",
    "    The following code allows a user to input an array and calculate either a time-series specific\n",
    "    entropy i.e. the nolds or a more general Shannon entropy as calculated in scipy. It calls \n",
    "    entropy functions in the file.\n",
    "    \n",
    "    \"\"\"\n",
    "    if method == 'scipy':\n",
    "        output = entropy_scipy(array, base=base)\n",
    "    elif method == 'nolds':\n",
    "        output = sampen(array)\n",
    "    else:\n",
    "        print('your method is not an option, we have defaulted to noal')\n",
    "        output = sampen(array)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_here = np.array([1,2,3,4,5,6,7,8,9,9,1,2,3,4,5,6,1,1,1,1,1,1,1,1,2,2,2,2,2,7,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_scipy(array_here, base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.entropy_scipy(array_here, base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropy_maker(\n",
    "        array_here,\n",
    "        method='nolds', base=None, \n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.entropy_maker(\n",
    "        array_here,\n",
    "        method='nolds', base=None, \n",
    "        \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to select where the FIRST entropy cut_off is, in terms of maximum entropy\n",
    "int_slider1 = widgets.IntSlider(\n",
    "    min=1, max=100, step=1,\n",
    "    description='percentage of maximum'\n",
    ")\n",
    "widgets.VBox(\n",
    "    [\n",
    "\n",
    "        int_slider1,\n",
    "\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to select where the cut_off is\n",
    "\n",
    "entropy_cutoff1 = widgets.Dropdown(\n",
    "    options=[\"Mean\",\"Half_range\"],\n",
    "    value='Mean',\n",
    "    description=\"Select Entropy Cut off\",\n",
    "    disabled=False,\n",
    ")\n",
    "display(entropy_cutoff1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_decision = (int_slider1.value)/100\n",
    "# high_decision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with new entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_for_ent(stralist):\n",
    "    rounded= np.round_(stralist, decimals = 5)\n",
    "    return rounded\n",
    "if time_view == 'Samples':\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start):int(end)])# replace with whole array of time series!\n",
    "else:\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start_s):int(end_s)])\n",
    "slice_length = 100\n",
    "def sliceIterator(lst, sliceLen):\n",
    "    for i in range(len(lst) - sliceLen + 1):\n",
    "        yield lst[i:i + sliceLen]\n",
    "index_hold = []\n",
    "for slice in sliceIterator(big_list, slice_length):\n",
    "    entropy_index = hf.entropy_scipy(slice)\n",
    "    index_hold.append(entropy_index)\n",
    "\n",
    "if entropy_cutoff1.value == 'Half_range':\n",
    "    ndecision_cutoff = (np.max(index_hold) + np.min(index_hold))/2\n",
    "else:# entropy_cutoff.value == 'Mean':\n",
    "    ndecision_cutoff = np.mean(index_hold)\n",
    "\n",
    "\n",
    "\n",
    "nrms_rolled = hf.vect_naive_rolling_rms(index_hold,100) # so rms is rms entropy\n",
    "\n",
    "nhigh_decision_cutoff = (nrms_rolled.max() - nrms_rolled.min())* high_decision +nrms_rolled.min()\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(nrms_rolled))],processed_data_emg[int(start):(int(start) + len(nrms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(nrms_rolled))],nrms_rolled)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(nrms_rolled))],hf.zero_one_for_jumps_base(nrms_rolled,ndecision_cutoff))\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(nrms_rolled))],hf.zero_one_for_jumps_base(nrms_rolled,nhigh_decision_cutoff), color= 'purple')\n",
    "    plt.axhline(y = ndecision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = nhigh_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    \n",
    "else:\n",
    "    y = converted_to_seconds\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(nrms_rolled)))], processed_data_emg[int(start_s):(int(start_s)+len(nrms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(nrms_rolled)))],nrms_rolled)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(nrms_rolled)))],hf.zero_one_for_jumps_base(nrms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(nrms_rolled)))],hf.zero_one_for_jumps_base(nrms_rolled,high_decision_cutoff), color = 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare to broken entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_for_ent(stralist):\n",
    "    rounded= np.round_(stralist, decimals = 5)\n",
    "    return rounded\n",
    "if time_view == 'Samples':\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start):int(end)])# replace with whole array of time series!\n",
    "else:\n",
    "    big_list = rounded_for_ent(processed_data_emg[int(start_s):int(end_s)])\n",
    "slice_length = 100\n",
    "def sliceIterator(lst, sliceLen):\n",
    "    for i in range(len(lst) - sliceLen + 1):\n",
    "        yield lst[i:i + sliceLen]\n",
    "index_hold = []\n",
    "for slice in sliceIterator(big_list, slice_length):\n",
    "    entropy_index = hf.entropical(slice)\n",
    "    index_hold.append(entropy_index)\n",
    "\n",
    "if entropy_cutoff1.value == 'Half_range':\n",
    "    decision_cutoff = (np.max(index_hold) + np.min(index_hold))/2\n",
    "else:# entropy_cutoff.value == 'Mean':\n",
    "    decision_cutoff = np.mean(index_hold)\n",
    "\n",
    "\n",
    "\n",
    "rms_rolled = hf.vect_naive_rolling_rms(index_hold,100) # so rms is rms entropy\n",
    "\n",
    "high_decision_cutoff = (rms_rolled.max() - rms_rolled.min())* high_decision +rms_rolled.min()\n",
    "if time_view == 'Samples':\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],processed_data_emg[int(start):(int(start) + len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],rms_rolled)\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_samples[int(start):(int(start) + len(rms_rolled))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color= 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    \n",
    "else:\n",
    "    y = converted_to_seconds\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))], processed_data_emg[int(start_s):(int(start_s)+len(rms_rolled))]*1000, alpha = 0.5)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],rms_rolled)\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,decision_cutoff))\n",
    "    plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color = 'purple')\n",
    "    plt.axhline(y = decision_cutoff, color = 'r', linestyle = '-')\n",
    "    plt.axhline(y = high_decision_cutoff, color = 'purple', linestyle = '-')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff), color = 'green', alpha=0.5)\n",
    "plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],hf.zero_one_for_jumps_base(nrms_rolled,nhigh_decision_cutoff), color = 'red', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(converted_to_seconds[int(start_s):(int(start_s)+int(len(rms_rolled)))],(np.array(hf.zero_one_for_jumps_base(rms_rolled,high_decision_cutoff)) - np.array(hf.zero_one_for_jumps_base(nrms_rolled,nhigh_decision_cutoff))), color = 'red', alpha=0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16+"
  },
  "vscode": {
   "interpreter": {
    "hash": "8109a244ef352616f4c4f029b1230a0cbb174b27c0c7598c58a1e884ef244c31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
