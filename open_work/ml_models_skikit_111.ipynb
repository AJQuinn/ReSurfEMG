{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "971e41d9",
   "metadata": {},
   "source": [
    "# ML for breathing - copy based on sci-kit learn 1.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475acdfa",
   "metadata": {},
   "source": [
    "Applying simple, common machine learning models to segments of EMG to predict whether segment was with our without respiratory muscle effort i.e. whether we are looking at a patient created breath."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375de351",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4813543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import resurfemg.helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91475bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.bad_end_cutter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf1d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = pandas.read_csv('../researcher_interface/ML_files/for_ml_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148f1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic ds\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#basic system\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "# math and signals\n",
    "import math\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.signal import find_peaks\n",
    "# demo stuff\n",
    "import ipywidgets as widgets\n",
    "import seaborn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e535941b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml stuff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our stuff\n",
    "from resurfemg.config import Config\n",
    "sys.path.insert(0, '../resurfemg')\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4f2ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new changes in our library i.e. the tmsisdk\n",
    "\n",
    "sys.path.insert(0, '../resurfemg')\n",
    "\n",
    "from tmsisdk_lite import Poly5Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85979523",
   "metadata": {},
   "source": [
    "## Import and set up data ( see ML_snippet_maker notebook for generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12403655",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "csv = pd.read_csv('../researcher_interface/ML_files/for_ml_csv.csv')\n",
    "csv2 = pd.read_csv('../researcher_interface/ML_files/for_ml_csv2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5413ce71",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992662a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = csv.dropna()\n",
    "csv2 = csv2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1976f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(csv2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63eeb0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "listicle = (list(range(999)))\n",
    "fu = list(map(str, listicle))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02a92db",
   "metadata": {},
   "source": [
    "We are going to add some random values for sanity checking... ML based on random values should give us an accuracy approaching 0.5 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3232754",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv2['std'] = csv2[fu].std(axis=1)\n",
    "csv2['max'] = csv2[fu].max(axis=1)\n",
    "csv2['min'] = csv2[fu].min(axis=1)\n",
    "csv2['mean'] = csv2[fu].mean(axis=1)\n",
    "csv2['entropy'] = csv2[fu].apply(entropy, axis=1)\n",
    "csv2['random1'] = csv2.apply(lambda x: np.random.randint(0,100-x['1'],1)[0], axis=1)\n",
    "csv2['random2'] = csv2.apply(lambda x: np.random.randint(0,100-x['2'],1)[0], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d54e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv['std'] = csv[fu].std(axis=1)\n",
    "csv['max'] = csv[fu].max(axis=1)\n",
    "csv['min'] = csv[fu].min(axis=1)\n",
    "csv['mean'] = csv[fu].mean(axis=1)\n",
    "csv['entropy'] = csv[fu].apply(entropy, axis =1)\n",
    "csv['random1'] = csv.apply(lambda x: np.random.randint(0,100-x['1'],1)[0], axis=1)\n",
    "csv['random2'] = csv.apply(lambda x: np.random.randint(0,100-x['2'],1)[0], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b4e2b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001fb6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv.loc[csv['label']== 'exhale', 'label'] = 0\n",
    "csv.loc[csv['label']== 'inhale', 'label'] = 1\n",
    "csv2.loc[csv2['label']== 'exhale', 'label'] = 0\n",
    "csv2.loc[csv2['label']== 'inhale', 'label'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29786b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to = pd.concat([csv,csv2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e96a3d",
   "metadata": {},
   "source": [
    "Now we have a data frame of the raw data (columns 0:999) from a bunch of EMG snippets (the rows) , and some features of them e.g. maximum value, mean etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cbae62",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(csv_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491a825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_to.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c50be3",
   "metadata": {},
   "source": [
    "# Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd007a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "loco = csv_to[['std','max', 'min', 'mean', 'entropy', 'random1', 'random2', 'label']]\n",
    "#seaborn.heatmap(loco)\n",
    "local = pd.DataFrame(loco)\n",
    "#print(type(\n",
    "local['label_int']= local['label'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcabf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#local.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a180f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "seaborn.heatmap(local.corr(), annot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280babb7",
   "metadata": {},
   "source": [
    "What is important to note is that in terms of our label, nothing even comes to 90% correlation. We need a more complex model than picking breaths b.y one parameter. Hence machine learning (ML) to the rescue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50018094",
   "metadata": {},
   "source": [
    "## ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44ad6072",
   "metadata": {},
   "source": [
    "You can pick more than one feature with the shift key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e309c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = widgets.SelectMultiple(\n",
    "    options=['std','max', 'min', 'mean', 'entropy', 'random1', 'random2'],\n",
    "    value=['min'],\n",
    "    #rows=10,\n",
    "    description='Features',\n",
    "    disabled=False\n",
    ")\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b489c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = list(features.value)\n",
    "features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b303d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = csv_to.drop('label', axis =1)\n",
    "X = X[features_list].values\n",
    "X = X.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25202a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879f107",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = csv_to['label'].values\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e75536",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86568626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train = sc.transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1496dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC(kernel= 'linear', random_state=1, C=0.1)\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bcde6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test)\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax= plt.subplot()\n",
    "seaborn.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['no breath', 'breath']); ax.yaxis.set_ticklabels(['no breath', 'breath']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58bbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(solver='liblinear', random_state=0)\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb3a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abaf299a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax= plt.subplot()\n",
    "seaborn.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['no breath', 'breath']); ax.yaxis.set_ticklabels(['no breath', 'breath']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d928e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = tree.DecisionTreeClassifier()\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f670145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea33a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd7f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "ax= plt.subplot()\n",
    "seaborn.heatmap(cm, annot=True, fmt='g', ax=ax);  \n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['no breath', 'breath']); ax.yaxis.set_ticklabels(['no breath', 'breath']);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce70aa64",
   "metadata": {},
   "source": [
    "OK, OK, a model with only max and entropy works 100%. This makes sense. Breaths are taller and more entropic..by our definition. What we would need to do is cut the breaths by expert hand, include some edge cases, then run this ML over that (potentially different) dataset. ALso remember we only had a few features in our dataset, of about 100 samples. What we can do it add 3X on data and features, with and without entropy. Will discuss with scientists exactly what features they want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001cd66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../ml_models/finalized_svm_model_in_111.sav'\n",
    "joblib.dump(svm, filename)\n",
    " \n",
    "# some time later...you can load the model from disk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9599b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '../ml_models/finalized_lr_model_in_111.sav'\n",
    "joblib.dump(lr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f313ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's explore how we might apply a model over a running emg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f34e8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_emg_directory = os.path.join('../not_pushed','topspin_data_anonymized')\n",
    "emg_pattern = os.path.join(root_emg_directory, '**/*.Poly5')\n",
    "emg_and_draeger_files = glob.glob(emg_pattern, recursive=True)\n",
    "\n",
    "emg_files = []\n",
    "draeger_files = []\n",
    "\n",
    "for file in emg_and_draeger_files:\n",
    "    if 'Draeger' in file:\n",
    "        draeger_files.append(file)\n",
    "    else:\n",
    "        emg_files.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18afa0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_numbers_strung = []\n",
    "for i in range(len(emg_files)):\n",
    "    list_of_numbers_strung.append(str(i))\n",
    "\n",
    "\n",
    "btn = widgets.Dropdown(\n",
    "    options=list_of_numbers_strung,\n",
    "    value='0',\n",
    "    description='Picked File:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(btn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840db752",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_chosen = int(btn.value)\n",
    "file_chosen = emg_files[number_chosen] \n",
    "print(\"The file you chose is:\",file_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc519c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_emg = Poly5Reader(file_chosen)\n",
    "data_samples= data_emg.samples\n",
    "emg_sample_rate = data_emg.sample_rate\n",
    "converted_to_seconds =  []\n",
    "converted_to_samples = []\n",
    "for i in range(len(data_samples[0])):\n",
    "    converted_to_seconds.append(i/emg_sample_rate)\n",
    "    converted_to_samples.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efbadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_samples[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedd2b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# set up plotn\n",
    "x = data_samples[:20000]\n",
    "fig, axis = plt.subplots(nrows = 3, ncols = 2, figsize=(16, 6))\n",
    "#ax.set_ylim([-4, 4])\n",
    "axis[0,0].grid(True)\n",
    "axis[0,0].plot(x[0])\n",
    "axis[0,0].set(title='leads in samples')\n",
    "axis[1,0].plot(x[1])\n",
    "axis[2,0].plot(x[2])\n",
    "axis[0,1].set(title='leads in seconds')\n",
    "axis[0,1].grid(True)\n",
    "axis[0,1].plot(converted_to_seconds,x[0])\n",
    "axis[1,1].plot(converted_to_seconds,x[1])\n",
    "axis[2,1].plot(converted_to_seconds,x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9acc7444",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt_emg_processed = hf.working_pipeline_pre_ml(data_samples, 'peaks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cae2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emg_processed = hf.working_pipeline_pre_ml(data_samples, 'heart')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d785e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(emg_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a64025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we had a final step in the snippet maker to make everything positive\n",
    "our_emg_processed = abs(emg_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad96be14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(our_emg_processed[:2000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec4afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#toy_list = list(range(1,10000))\n",
    "#toy_array = np.array(toy_list)\n",
    "toy_array = our_emg_processed[:80000]\n",
    "index_ml_hold = []\n",
    "predictions_made = []\n",
    "holder = []\n",
    "for slice in hf.slices_jump_slider(toy_array, 1000,1):\n",
    "    ml_index_feature1 = slice.mean() #close to mean\n",
    "    ml_index_feature2 = entropy(slice)\n",
    "    holder.append(slice)\n",
    "    ml_index_test= [ml_index_feature1, ml_index_feature2]\n",
    "\n",
    "    index_ml_hold.append(ml_index_test)\n",
    "#     # need to reshape array\n",
    "X_test_live = index_ml_hold\n",
    "X_test_live = sc.transform(X_test_live)\n",
    "predictions_svm = svm.predict(X_test_live)\n",
    "predictions_lr = lr.predict(X_test_live)\n",
    "    #predictions_made.append(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e26cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(index_ml_hold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36b5f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95797ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predictions_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea58f75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(predictions_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c7bf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(predictions_svm, color='purple', alpha= 0.5)\n",
    "plt.plot(predictions_lr, color='green',  alpha= 0.5)\n",
    "plt.plot(toy_array*1000, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa43d7ae",
   "metadata": {},
   "source": [
    "Remember at each point it looks 1000 forward, and makes a prediciton over the whole array, this we should probably shift the prediction arrays forward by 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da866175",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifter = np.zeros(500) +3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e3b3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_lr = np.hstack((shifter, predictions_lr))\n",
    "shifted_svm = np.hstack((shifter, predictions_svm)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3dc4360",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(shifted_svm, color='purple', alpha= 0.5)\n",
    "plt.plot(shifted_lr, color='green',  alpha= 0.5)\n",
    "plt.plot(toy_array*1000, alpha=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87caeff",
   "metadata": {},
   "source": [
    "Perfect predictions? Let's try more cases, and see how our models do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb85a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "150000/2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4902b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "8109a244ef352616f4c4f029b1230a0cbb174b27c0c7598c58a1e884ef244c31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
